{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_09 (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ambicapvs/ambica_info5731_spring2021/blob/main/In_class_exercise_09_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp8DrEiNsdKh"
      },
      "source": [
        "# **The ninth in-class-exercise (20 points in total, 4/16/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bYk4dlwsdKr"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhjSJN5OsdKs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "1edb5276-2ddc-4f7f-afb9-9656cc87d3ba"
      },
      "source": [
        "#loading train and test data\n",
        "import pandas as pd\n",
        "train_data = open(\"/content/stsa-train.txt\").read()\n",
        "train_labels, train_text = [], []\n",
        "test_labels, test_text = [], []\n",
        "for i, line in enumerate(train_data.split(\"\\n\")):\n",
        "    content = line.split(\" \")\n",
        "    train_labels.append(content[0])\n",
        "    train_text.append(\" \".join(content[1:]))\n",
        "train_dataframe = pd.DataFrame (list(zip(train_text, train_labels)) , columns = ['text', 'label'])\n",
        "train_dataframe.head(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>campanella gets the tone just right -- funny i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>a fan film that for the uninitiated plays bett...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>béart and berling are both superb , while hupp...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>a little less extreme than in the past , with ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>the film is strictly routine .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text label\n",
              "0  a stirring , funny and finally transporting re...     1\n",
              "1  apparently reassembled from the cutting-room f...     0\n",
              "2  they presume their audience wo n't sit still f...     0\n",
              "3  this is a visually stunning rumination on love...     1\n",
              "4  jonathan parker 's bartleby should have been t...     1\n",
              "5  campanella gets the tone just right -- funny i...     1\n",
              "6  a fan film that for the uninitiated plays bett...     0\n",
              "7  béart and berling are both superb , while hupp...     1\n",
              "8  a little less extreme than in the past , with ...     0\n",
              "9                     the film is strictly routine .     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "92Gkf9QX8Noz",
        "outputId": "953cd98c-5dea-4eb9-ef5e-d65e5845d949"
      },
      "source": [
        "# test data\n",
        "test_data = open(\"/content/stsa-test.txt\").read()\n",
        "test_labels, test_text = [], []\n",
        "for i, line in enumerate(test_data.split(\"\\n\")):\n",
        "    content = line.split(\" \")\n",
        "    test_labels.append(content[0])\n",
        "    test_text.append(\" \".join(content[1:]))\n",
        "# create a dataframe using texts and lables\n",
        "test_dataframe = pd.DataFrame (list(zip(test_text, test_labels)) , columns = ['text', 'label'])\n",
        "test_dataframe.head(10)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>take care of my cat offers a refreshingly diff...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>acting , particularly by tambor , almost makes...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>the movie exists for its soccer action and its...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>arnold 's jump from little screen to big will ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>if this holiday movie is supposed to be a gift...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text label\n",
              "0     no movement , no yuks , not much of anything .     0\n",
              "1  a gob of drivel so sickly sweet , even the eag...     0\n",
              "2  gangs of new york is an unapologetic mess , wh...     0\n",
              "3  we never really feel involved with the story ,...     0\n",
              "4            this is one of polanski 's best films .     1\n",
              "5  take care of my cat offers a refreshingly diff...     1\n",
              "6  acting , particularly by tambor , almost makes...     0\n",
              "7  the movie exists for its soccer action and its...     1\n",
              "8  arnold 's jump from little screen to big will ...     0\n",
              "9  if this holiday movie is supposed to be a gift...     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_luvHKX6ukte",
        "outputId": "2db09d83-2e84-4da6-b313-64b821636633"
      },
      "source": [
        "#Imports\n",
        "from textblob import Word\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "from textblob import TextBlob\n",
        "import requests\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "#data cleaning\n",
        "def DataCleaning(dataframe):\n",
        "  dataframe[\"punctuationremoval\"] = dataframe[\"text\"].str.replace('[^\\w\\s]','')\n",
        "  #remove special chars\n",
        "  dataframe['special_chars'] = dataframe[\"punctuationremoval\"].str.replace('[^A-Za-z0-9 ]+','')\n",
        "  #remove Numbers\n",
        "  dataframe['nums_removed'] = dataframe[\"special_chars\"].str.replace('[^A-Za-z ]+','')\n",
        "  #extract stopwords\n",
        "  data = requests.get(\"https://gist.githubusercontent.com/sebleier/554280/raw/7e0e4a1ce04c2bb7bd41089c9821dbcf6d0c786c/NLTK's%2520list%2520of%2520english%2520stopwords\")\n",
        "  a = data.text\n",
        "  stop = a.split()\n",
        "  #stopwords\n",
        "  dataframe['stopwords'] = dataframe[\"nums_removed\"].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "  #lowercase\n",
        "  dataframe[\"lower_case\"] = dataframe['stopwords'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "  #tokenizing data for next step - stemming\n",
        "  dataframe[\"tokenization\"] = dataframe[\"lower_case\"].apply(lambda x: TextBlob(x).words)\n",
        "  #stemming\n",
        "  st = PorterStemmer()\n",
        "  dataframe[\"stemming\"]= dataframe[\"tokenization\"].apply(lambda x: \" \".join([st.stem(word) for word in x]))\n",
        "  #Lemmatization\n",
        "  dataframe[\"lemmatization\"] = dataframe[\"stemming\"].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "  return dataframe\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AT58-0VbwC7G",
        "outputId": "60ad600f-1eee-41ba-d69b-9447fe2f1a24"
      },
      "source": [
        "traindf = DataCleaning(train_dataframe)\n",
        "traindf.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>punctuationremoval</th>\n",
              "      <th>special_chars</th>\n",
              "      <th>nums_removed</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>lower_case</th>\n",
              "      <th>tokenization</th>\n",
              "      <th>stemming</th>\n",
              "      <th>lemmatization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "      <td>a stirring  funny and finally transporting rei...</td>\n",
              "      <td>a stirring  funny and finally transporting rei...</td>\n",
              "      <td>a stirring  funny and finally transporting rei...</td>\n",
              "      <td>stirring funny finally transporting reimaginin...</td>\n",
              "      <td>stirring funny finally transporting reimaginin...</td>\n",
              "      <td>[stirring, funny, finally, transporting, reima...</td>\n",
              "      <td>stir funni final transport reimagin beauti bea...</td>\n",
              "      <td>stir funni final transport reimagin beauti bea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>0</td>\n",
              "      <td>apparently reassembled from the cuttingroom fl...</td>\n",
              "      <td>apparently reassembled from the cuttingroom fl...</td>\n",
              "      <td>apparently reassembled from the cuttingroom fl...</td>\n",
              "      <td>apparently reassembled cuttingroom floor given...</td>\n",
              "      <td>apparently reassembled cuttingroom floor given...</td>\n",
              "      <td>[apparently, reassembled, cuttingroom, floor, ...</td>\n",
              "      <td>appar reassembl cuttingroom floor given daytim...</td>\n",
              "      <td>appar reassembl cuttingroom floor given daytim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "      <td>they presume their audience wo nt sit still fo...</td>\n",
              "      <td>they presume their audience wo nt sit still fo...</td>\n",
              "      <td>they presume their audience wo nt sit still fo...</td>\n",
              "      <td>presume audience wo nt sit still sociology les...</td>\n",
              "      <td>presume audience wo nt sit still sociology les...</td>\n",
              "      <td>[presume, audience, wo, nt, sit, still, sociol...</td>\n",
              "      <td>presum audienc wo nt sit still sociolog lesson...</td>\n",
              "      <td>presum audienc wo nt sit still sociolog lesson...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>visually stunning rumination love memory histo...</td>\n",
              "      <td>visually stunning rumination love memory histo...</td>\n",
              "      <td>[visually, stunning, rumination, love, memory,...</td>\n",
              "      <td>visual stun rumin love memori histori war art ...</td>\n",
              "      <td>visual stun rumin love memori histori war art ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "      <td>jonathan parker s bartleby should have been th...</td>\n",
              "      <td>jonathan parker s bartleby should have been th...</td>\n",
              "      <td>jonathan parker s bartleby should have been th...</td>\n",
              "      <td>jonathan parker bartleby beallendall modernoff...</td>\n",
              "      <td>jonathan parker bartleby beallendall modernoff...</td>\n",
              "      <td>[jonathan, parker, bartleby, beallendall, mode...</td>\n",
              "      <td>jonathan parker bartlebi beallendal modernoffi...</td>\n",
              "      <td>jonathan parker bartlebi beallendal modernoffi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>campanella gets the tone just right -- funny i...</td>\n",
              "      <td>1</td>\n",
              "      <td>campanella gets the tone just right  funny in ...</td>\n",
              "      <td>campanella gets the tone just right  funny in ...</td>\n",
              "      <td>campanella gets the tone just right  funny in ...</td>\n",
              "      <td>campanella gets tone right funny middle sad mi...</td>\n",
              "      <td>campanella gets tone right funny middle sad mi...</td>\n",
              "      <td>[campanella, gets, tone, right, funny, middle,...</td>\n",
              "      <td>campanella get tone right funni middl sad midd...</td>\n",
              "      <td>campanella get tone right funni middl sad midd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>a fan film that for the uninitiated plays bett...</td>\n",
              "      <td>0</td>\n",
              "      <td>a fan film that for the uninitiated plays bett...</td>\n",
              "      <td>a fan film that for the uninitiated plays bett...</td>\n",
              "      <td>a fan film that for the uninitiated plays bett...</td>\n",
              "      <td>fan film uninitiated plays better video sound ...</td>\n",
              "      <td>fan film uninitiated plays better video sound ...</td>\n",
              "      <td>[fan, film, uninitiated, plays, better, video,...</td>\n",
              "      <td>fan film uniniti play better video sound turn</td>\n",
              "      <td>fan film uniniti play better video sound turn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>béart and berling are both superb , while hupp...</td>\n",
              "      <td>1</td>\n",
              "      <td>béart and berling are both superb  while huppe...</td>\n",
              "      <td>bart and berling are both superb  while hupper...</td>\n",
              "      <td>bart and berling are both superb  while hupper...</td>\n",
              "      <td>bart berling superb huppert magnificent</td>\n",
              "      <td>bart berling superb huppert magnificent</td>\n",
              "      <td>[bart, berling, superb, huppert, magnificent]</td>\n",
              "      <td>bart berl superb huppert magnific</td>\n",
              "      <td>bart berl superb huppert magnific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>a little less extreme than in the past , with ...</td>\n",
              "      <td>0</td>\n",
              "      <td>a little less extreme than in the past  with l...</td>\n",
              "      <td>a little less extreme than in the past  with l...</td>\n",
              "      <td>a little less extreme than in the past  with l...</td>\n",
              "      <td>little less extreme past longer exposition seq...</td>\n",
              "      <td>little less extreme past longer exposition seq...</td>\n",
              "      <td>[little, less, extreme, past, longer, expositi...</td>\n",
              "      <td>littl less extrem past longer exposit sequenc ...</td>\n",
              "      <td>littl le extrem past longer exposit sequenc fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>the film is strictly routine .</td>\n",
              "      <td>0</td>\n",
              "      <td>the film is strictly routine</td>\n",
              "      <td>the film is strictly routine</td>\n",
              "      <td>the film is strictly routine</td>\n",
              "      <td>film strictly routine</td>\n",
              "      <td>film strictly routine</td>\n",
              "      <td>[film, strictly, routine]</td>\n",
              "      <td>film strictli routin</td>\n",
              "      <td>film strictli routin</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                      lemmatization\n",
              "0  a stirring , funny and finally transporting re...  ...  stir funni final transport reimagin beauti bea...\n",
              "1  apparently reassembled from the cutting-room f...  ...  appar reassembl cuttingroom floor given daytim...\n",
              "2  they presume their audience wo n't sit still f...  ...  presum audienc wo nt sit still sociolog lesson...\n",
              "3  this is a visually stunning rumination on love...  ...  visual stun rumin love memori histori war art ...\n",
              "4  jonathan parker 's bartleby should have been t...  ...  jonathan parker bartlebi beallendal modernoffi...\n",
              "5  campanella gets the tone just right -- funny i...  ...  campanella get tone right funni middl sad midd...\n",
              "6  a fan film that for the uninitiated plays bett...  ...      fan film uniniti play better video sound turn\n",
              "7  béart and berling are both superb , while hupp...  ...                  bart berl superb huppert magnific\n",
              "8  a little less extreme than in the past , with ...  ...  littl le extrem past longer exposit sequenc fe...\n",
              "9                     the film is strictly routine .  ...                               film strictli routin\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Yq0FJJ3zwaZH",
        "outputId": "40cc6783-340a-4a44-845f-9e3df589a8a3"
      },
      "source": [
        "testdf = DataCleaning(test_dataframe)\n",
        "testdf.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>punctuationremoval</th>\n",
              "      <th>special_chars</th>\n",
              "      <th>nums_removed</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>lower_case</th>\n",
              "      <th>tokenization</th>\n",
              "      <th>stemming</th>\n",
              "      <th>lemmatization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>0</td>\n",
              "      <td>no movement  no yuks  not much of anything</td>\n",
              "      <td>no movement  no yuks  not much of anything</td>\n",
              "      <td>no movement  no yuks  not much of anything</td>\n",
              "      <td>movement yuks much anything</td>\n",
              "      <td>movement yuks much anything</td>\n",
              "      <td>[movement, yuks, much, anything]</td>\n",
              "      <td>movement yuk much anyth</td>\n",
              "      <td>movement yuk much anyth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>0</td>\n",
              "      <td>a gob of drivel so sickly sweet  even the eage...</td>\n",
              "      <td>a gob of drivel so sickly sweet  even the eage...</td>\n",
              "      <td>a gob of drivel so sickly sweet  even the eage...</td>\n",
              "      <td>gob drivel sickly sweet even eager consumers m...</td>\n",
              "      <td>gob drivel sickly sweet even eager consumers m...</td>\n",
              "      <td>[gob, drivel, sickly, sweet, even, eager, cons...</td>\n",
              "      <td>gob drivel sickli sweet even eager consum moor...</td>\n",
              "      <td>gob drivel sickli sweet even eager consum moor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>0</td>\n",
              "      <td>gangs of new york is an unapologetic mess  who...</td>\n",
              "      <td>gangs of new york is an unapologetic mess  who...</td>\n",
              "      <td>gangs of new york is an unapologetic mess  who...</td>\n",
              "      <td>gangs new york unapologetic mess whose saving ...</td>\n",
              "      <td>gangs new york unapologetic mess whose saving ...</td>\n",
              "      <td>[gangs, new, york, unapologetic, mess, whose, ...</td>\n",
              "      <td>gang new york unapologet mess whose save grace...</td>\n",
              "      <td>gang new york unapologet mess whose save grace...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>0</td>\n",
              "      <td>we never really feel involved with the story  ...</td>\n",
              "      <td>we never really feel involved with the story  ...</td>\n",
              "      <td>we never really feel involved with the story  ...</td>\n",
              "      <td>never really feel involved story ideas remain ...</td>\n",
              "      <td>never really feel involved story ideas remain ...</td>\n",
              "      <td>[never, really, feel, involved, story, ideas, ...</td>\n",
              "      <td>never realli feel involv stori idea remain abs...</td>\n",
              "      <td>never realli feel involv stori idea remain abs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>1</td>\n",
              "      <td>this is one of polanski s best films</td>\n",
              "      <td>this is one of polanski s best films</td>\n",
              "      <td>this is one of polanski s best films</td>\n",
              "      <td>one polanski best films</td>\n",
              "      <td>one polanski best films</td>\n",
              "      <td>[one, polanski, best, films]</td>\n",
              "      <td>one polanski best film</td>\n",
              "      <td>one polanski best film</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>take care of my cat offers a refreshingly diff...</td>\n",
              "      <td>1</td>\n",
              "      <td>take care of my cat offers a refreshingly diff...</td>\n",
              "      <td>take care of my cat offers a refreshingly diff...</td>\n",
              "      <td>take care of my cat offers a refreshingly diff...</td>\n",
              "      <td>take care cat offers refreshingly different sl...</td>\n",
              "      <td>take care cat offers refreshingly different sl...</td>\n",
              "      <td>[take, care, cat, offers, refreshingly, differ...</td>\n",
              "      <td>take care cat offer refreshingli differ slice ...</td>\n",
              "      <td>take care cat offer refreshingli differ slice ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>acting , particularly by tambor , almost makes...</td>\n",
              "      <td>0</td>\n",
              "      <td>acting  particularly by tambor  almost makes  ...</td>\n",
              "      <td>acting  particularly by tambor  almost makes  ...</td>\n",
              "      <td>acting  particularly by tambor  almost makes  ...</td>\n",
              "      <td>acting particularly tambor almost makes never ...</td>\n",
              "      <td>acting particularly tambor almost makes never ...</td>\n",
              "      <td>[acting, particularly, tambor, almost, makes, ...</td>\n",
              "      <td>act particularli tambor almost make never wort...</td>\n",
              "      <td>act particularli tambor almost make never wort...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>the movie exists for its soccer action and its...</td>\n",
              "      <td>1</td>\n",
              "      <td>the movie exists for its soccer action and its...</td>\n",
              "      <td>the movie exists for its soccer action and its...</td>\n",
              "      <td>the movie exists for its soccer action and its...</td>\n",
              "      <td>movie exists soccer action fine acting</td>\n",
              "      <td>movie exists soccer action fine acting</td>\n",
              "      <td>[movie, exists, soccer, action, fine, acting]</td>\n",
              "      <td>movi exist soccer action fine act</td>\n",
              "      <td>movi exist soccer action fine act</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>arnold 's jump from little screen to big will ...</td>\n",
              "      <td>0</td>\n",
              "      <td>arnold s jump from little screen to big will l...</td>\n",
              "      <td>arnold s jump from little screen to big will l...</td>\n",
              "      <td>arnold s jump from little screen to big will l...</td>\n",
              "      <td>arnold jump little screen big leave frowns faces</td>\n",
              "      <td>arnold jump little screen big leave frowns faces</td>\n",
              "      <td>[arnold, jump, little, screen, big, leave, fro...</td>\n",
              "      <td>arnold jump littl screen big leav frown face</td>\n",
              "      <td>arnold jump littl screen big leav frown face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>if this holiday movie is supposed to be a gift...</td>\n",
              "      <td>0</td>\n",
              "      <td>if this holiday movie is supposed to be a gift...</td>\n",
              "      <td>if this holiday movie is supposed to be a gift...</td>\n",
              "      <td>if this holiday movie is supposed to be a gift...</td>\n",
              "      <td>holiday movie supposed gift somebody unwrapped...</td>\n",
              "      <td>holiday movie supposed gift somebody unwrapped...</td>\n",
              "      <td>[holiday, movie, supposed, gift, somebody, unw...</td>\n",
              "      <td>holiday movi suppos gift somebodi unwrap earli...</td>\n",
              "      <td>holiday movi suppos gift somebodi unwrap earli...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                      lemmatization\n",
              "0     no movement , no yuks , not much of anything .  ...                            movement yuk much anyth\n",
              "1  a gob of drivel so sickly sweet , even the eag...  ...  gob drivel sickli sweet even eager consum moor...\n",
              "2  gangs of new york is an unapologetic mess , wh...  ...  gang new york unapologet mess whose save grace...\n",
              "3  we never really feel involved with the story ,...  ...  never realli feel involv stori idea remain abs...\n",
              "4            this is one of polanski 's best films .  ...                             one polanski best film\n",
              "5  take care of my cat offers a refreshingly diff...  ...  take care cat offer refreshingli differ slice ...\n",
              "6  acting , particularly by tambor , almost makes...  ...  act particularli tambor almost make never wort...\n",
              "7  the movie exists for its soccer action and its...  ...                  movi exist soccer action fine act\n",
              "8  arnold 's jump from little screen to big will ...  ...       arnold jump littl screen big leav frown face\n",
              "9  if this holiday movie is supposed to be a gift...  ...  holiday movi suppos gift somebodi unwrap earli...\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1olQhXqby-_L"
      },
      "source": [
        "#TF-IDF vectorization\n",
        "from sklearn import model_selection, preprocessing, naive_bayes, metrics, svm\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word')\n",
        "tfidf_vect.fit(traindf['lemmatization'])\n",
        "x_tfidf =  tfidf_vect.transform(traindf['lemmatization'])\n",
        "vect_test = TfidfVectorizer(analyzer='word', vocabulary = tfidf_vect.vocabulary_)\n",
        "vect_test.fit(testdf['lemmatization'])\n",
        "test_x = vect_test.transform(testdf['lemmatization'])\n",
        "test_y = testdf['label']\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3IKVzW0zMki"
      },
      "source": [
        "#split the dataset into training and validation datasets \n",
        "from sklearn import model_selection, preprocessing\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(x_tfidf, traindf['label'], test_size=0.2)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxG93oUWnJdU"
      },
      "source": [
        "#Function for Cross Validation Score\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn import metrics\n",
        "def get_cross_score(modelName, x, y):\n",
        "  scoring = 'accuracy'\n",
        "  kfold = KFold(10, random_state = 7,shuffle=True)\n",
        "  cross_score = cross_val_score(modelName, x, y, cv=kfold).mean()\n",
        "  return cross_score\n",
        "#Function for various scores - accuracy, precision, recall and F1\n",
        "def get_metrics(predictions, test_data_y):\n",
        "  accuracy = metrics.accuracy_score(predictions, test_data_y)\n",
        "  precision = metrics.precision_score(predictions, test_data_y, pos_label='positive', average='micro')\n",
        "  recall = metrics.recall_score(predictions, test_data_y, pos_label='positive', average='micro')\n",
        "  f1 = metrics.f1_score(predictions, test_data_y, pos_label='positive', average='micro')\n",
        "  return accuracy, precision, recall, f1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zr7WlLhpJxd",
        "outputId": "129f2f39-f698-409e-edb3-c5cb2a99a1f4"
      },
      "source": [
        "#Multinomial NB Model\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "def Naive_bayes_model(x1, y1, x2, y2):\n",
        "  nb_model = naive_bayes.MultinomialNB()\n",
        "  nb_model.fit(x1, y1)\n",
        "  nb_predicts = nb_model.predict(x2)\n",
        "  accuracy, precision, recall, f1 = get_metrics(nb_predicts, y2)\n",
        "  nb_score = get_cross_score(nb_model, x2, y2)\n",
        "  return accuracy, precision, recall, f1, nb_score\n",
        "\n",
        "accuracy_nb, precision_nb, recall_nb, f1_nb, nb_score = Naive_bayes_model(train_x, train_y, valid_x, valid_y)\n",
        "print(\"Printing results for Naive Bayes Model:\\n\")\n",
        "print(\"Training Data:\\nAccuracy : {0}\\nPrecision : {1}\\nRecall : {2}\\nF1 : {3}\\nCross validation Score : {4}\".format(accuracy_nb, precision_nb, recall_nb, f1_nb, nb_score))\n",
        "accuracy_nbt, precision_nbt, recall_nbt, f1_nbt, nb_scoret = Naive_bayes_model(train_x, train_y, test_x, test_y)\n",
        "print(\"\\nTest Data:\\nAccuracy : {0}\\nPrecision : {1}\\nRecall : {2}\\nF1 : {3}\\nCross validation Score : {4}\".format(accuracy_nbt, precision_nbt, recall_nbt, f1_nbt, nb_scoret))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing results for Naive Bayes Model:\n",
            "\n",
            "Training Data:\n",
            "Accuracy : 0.7812274368231047\n",
            "Precision : 0.7812274368231047\n",
            "Recall : 0.7812274368231047\n",
            "F1 : 0.7812274368231046\n",
            "Cross validation Score : 0.7126159941611927\n",
            "\n",
            "Test Data:\n",
            "Accuracy : 0.7854006586169044\n",
            "Precision : 0.7854006586169044\n",
            "Recall : 0.7854006586169044\n",
            "F1 : 0.7854006586169044\n",
            "Cross validation Score : 0.7365219479973579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kerj_29KvL2B"
      },
      "source": [
        "**SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKkxB0bYvQZ7",
        "outputId": "1af141c9-f43e-4e94-9309-a7336a766a59"
      },
      "source": [
        "#SVM model\n",
        "\n",
        "def SVM_model_Fun(x1, y1, x2, y2):\n",
        "  svm_model = svm.SVC()\n",
        "  svm_model.fit(x1, y1)\n",
        "  svm_predicts = svm_model.predict(x2)\n",
        "  accuracy, precision, recall, f1 = get_metrics(svm_predicts, y2)\n",
        "  svm_score = get_cross_score(svm_model, x2, y2)\n",
        "  return accuracy, precision, recall, f1, svm_score\n",
        "\n",
        "accuracy_svm, precision_svm, recall_svm, f1_svm, svm_score = SVM_model_Fun(train_x, train_y, valid_x, valid_y)\n",
        "print(\"Printing results for SVM Model:\\n\")\n",
        "print(\"Training Data:\\nAccuracy : {0}\\nPrecision : {1}\\nRecall : {2}\\nF1 : {3}\\nCross validation Score : {4}\".format(accuracy_svm, precision_svm, recall_svm, f1_svm, svm_score))\n",
        "accuracy_svmt, precision_svmt, recall_svmt, f1_svmt, svm_scoret = SVM_model_Fun(train_x, train_y, test_x, test_y)\n",
        "print(\"\\nTest Data:\\nAccuracy : {0}\\nPrecision : {1}\\nRecall : {2}\\nF1 : {3}\\nCross validation Score : {4}\".format(accuracy_svmt, precision_svmt, recall_svmt, f1_svmt, svm_scoret))\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing results for SVM Model:\n",
            "\n",
            "Training Data:\n",
            "Accuracy : 0.7805054151624549\n",
            "Precision : 0.7805054151624549\n",
            "Recall : 0.7805054151624549\n",
            "F1 : 0.7805054151624549\n",
            "Cross validation Score : 0.7227400688145136\n",
            "\n",
            "Test Data:\n",
            "Accuracy : 0.7930845225027442\n",
            "Precision : 0.7930845225027442\n",
            "Recall : 0.7930845225027442\n",
            "F1 : 0.7930845225027442\n",
            "Cross validation Score : 0.7425689065033328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFwGwclN5-Cm"
      },
      "source": [
        "**KNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKgEA10a5_9d",
        "outputId": "7d78b856-ccd8-4eb4-acef-e6eac3108332"
      },
      "source": [
        "#KNN model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "def KNN_model_Fun(x1, y1, x2, y2):\n",
        "  knn_model = KNeighborsClassifier(n_neighbors = 15)\n",
        "  knn_model.fit(x1, y1)\n",
        "  knn_predicts = knn_model.predict(x2)\n",
        "  accuracy, precision, recall, f1 = get_metrics(knn_predicts, y2)\n",
        "  knn_score = get_cross_score(knn_model, x2, y2)\n",
        "  return accuracy, precision, recall, f1, knn_score\n",
        "\n",
        "accuracy_knn, precision_knn, recall_knn, f1_knn, knn_score = KNN_model_Fun(train_x, train_y, valid_x, valid_y)\n",
        "print(\"Printing results for KNN Model:\\n\")\n",
        "print(\"Training Data:\\nAccuracy : {0}\\nPrecision : {1}\\nRecall : {2}\\nF1 : {3}\\nCross validation Score : {4}\".format(accuracy_knn, precision_knn, recall_knn, f1_knn, knn_score))\n",
        "accuracy_knnt, precision_knnt, recall_knnt, f1_knnt, knn_scoret = KNN_model_Fun(train_x, train_y, test_x, test_y)\n",
        "print(\"\\nTest Data:\\nAccuracy : {0}\\nPrecision : {1}\\nRecall : {2}\\nF1 : {3}\\nCross validation Score : {4}\".format(accuracy_knnt, precision_knnt, recall_knnt, f1_knnt, knn_scoret))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing results for KNN Model:\n",
            "\n",
            "Training Data:\n",
            "Accuracy : 0.7371841155234657\n",
            "Precision : 0.7371841155234657\n",
            "Recall : 0.7371841155234657\n",
            "F1 : 0.7371841155234657\n",
            "Cross validation Score : 0.6764883745177771\n",
            "\n",
            "Test Data:\n",
            "Accuracy : 0.7354555433589463\n",
            "Precision : 0.7354555433589463\n",
            "Recall : 0.7354555433589463\n",
            "F1 : 0.7354555433589463\n",
            "Cross validation Score : 0.6465381612922597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpoRSKp7xLjO"
      },
      "source": [
        "**DECISION TREE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOiGEyrAxJXA",
        "outputId": "8bccf828-e96f-40fc-a56e-a1d2332efd7a"
      },
      "source": [
        "# decision tree\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "def decision_Tree(x1, y1, x2, y2):\n",
        "  dt_model = DecisionTreeClassifier()\n",
        "  dt_model.fit(x1, y1)\n",
        "  dt_predicts = dt_model.predict(x2)\n",
        "  accuracy, precision, recall, f1 = get_metrics(dt_predicts, y2)\n",
        "  dt_score = get_cross_score(dt_model, x2, y2)\n",
        "  return accuracy, precision, recall, f1, dt_score\n",
        "\n",
        "accuracy_dt, precision_dt, recall_dt, f1_dt, dt_score = decision_Tree(train_x, train_y, valid_x, valid_y)\n",
        "print(\"Printing results for Decision Tree:\\n\")\n",
        "print(\"Training Data:\\nAccuracy : {0}\\nPrecision : {1}\\nRecall : {2}\\nF1 : {3}\\nCross validation Score : {4}\".format(accuracy_dt, precision_dt, recall_dt, f1_dt, dt_score))\n",
        "accuracy_dtt, precision_dtt, recall_dtt, f1_dtt, dt_scoret = decision_Tree(train_x, train_y, test_x, test_y)\n",
        "print(\"\\nTest Data:\\nAccuracy : {0}\\nPrecision : {1}\\nRecall : {2}\\nF1 : {3}\\nCross validation Score : {4}\".format(accuracy_dtt, precision_dtt, recall_dtt, f1_dtt, dt_scoret))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing results for Decision Tree:\n",
            "\n",
            "Training Data:\n",
            "Accuracy : 0.6750902527075813\n",
            "Precision : 0.6750902527075813\n",
            "Recall : 0.6750902527075813\n",
            "F1 : 0.6750902527075813\n",
            "Cross validation Score : 0.5371806902304244\n",
            "\n",
            "Test Data:\n",
            "Accuracy : 0.677277716794731\n",
            "Precision : 0.677277716794731\n",
            "Recall : 0.677277716794731\n",
            "F1 : 0.677277716794731\n",
            "Cross validation Score : 0.650354290518225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpAchDz1yVQ-"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILZkH3SbyObp",
        "outputId": "1f5703a0-d1db-4cf0-d6f9-1fbaca6a5a46"
      },
      "source": [
        "#random Forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "def random_Forest(x1, y1, x2, y2):\n",
        "  rf_model = RandomForestClassifier()\n",
        "  rf_model.fit(x1, y1)\n",
        "  rf_predicts = rf_model.predict(x2)\n",
        "  accuracy, precision, recall, f1 = get_metrics(rf_predicts, y2)\n",
        "  rf_score = get_cross_score(rf_model, x2, y2)\n",
        "  return accuracy, precision, recall, f1, rf_score\n",
        "\n",
        "accuracy_rf, precision_rf, recall_rf, f1_rf, rf_score = random_Forest(train_x, train_y, valid_x, valid_y)\n",
        "print(\"Printing results for Random Forest:\\n\")\n",
        "print(\"Training Data:\\nAccuracy : {0}\\nPrecision : {1}\\nRecall : {2}\\nF1 : {3}\\nCross validation Score : {4}\".format(accuracy_rf, precision_rf, recall_rf, f1_rf, rf_score))\n",
        "accuracy_rft, precision_rft, recall_rft, f1_rft, rft_score = random_Forest(train_x, train_y, test_x, test_y)\n",
        "print(\"\\nTest Data:\\nAccuracy : {0}\\nPrecision : {1}\\nRecall : {2}\\nF1 : {3}\\nCross validation Score : {4}\".format(accuracy_rft, precision_rft, recall_rft, f1_rft, rft_score))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing results for Random Forest:\n",
            "\n",
            "Training Data:\n",
            "Accuracy : 0.7537906137184116\n",
            "Precision : 0.7537906137184116\n",
            "Recall : 0.7537906137184116\n",
            "F1 : 0.7537906137184115\n",
            "Cross validation Score : 0.6851736002502348\n",
            "\n",
            "Test Data:\n",
            "Accuracy : 0.7557628979143798\n",
            "Precision : 0.7557628979143798\n",
            "Recall : 0.7557628979143798\n",
            "F1 : 0.7557628979143798\n",
            "Cross validation Score : 0.6833123160992014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPi-dGRL0Fni"
      },
      "source": [
        "**XG Boost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pji5ArZe0ElF",
        "outputId": "9adc40f6-6a80-4ba6-d448-2951dc42d9da"
      },
      "source": [
        "#XG Boost\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "def XGBoostmodel(x1, y1, x2, y2):\n",
        "  xg_model = XGBClassifier()\n",
        "  xg_model.fit(x1, y1)\n",
        "  xg_predicts = xg_model.predict(x2)\n",
        "  accuracy, precision, recall, f1 = get_metrics(xg_predicts, y2)\n",
        "  xg_score = get_cross_score(XGBClassifier(), valid_x, valid_y)\n",
        "  return accuracy, precision, recall, f1, xg_score\n",
        "\n",
        "accuracy_xg, precision_xg, recall_xg, f1_xg, xg_score = XGBoostmodel(train_x, train_y, valid_x, valid_y)\n",
        "print(\"Printing results for XG Boost:\\n\")\n",
        "print(\"Training Data:\\nAccuracy : {0}\\nPrecision : {1}\\nRecall : {2}\\nF1 : {3}\\nCross validation Score : {4}\".format(accuracy_xg, precision_xg, recall_xg, f1_xg, xg_score))\n",
        "accuracy_xgt, precision_xgt, recall_xgt, f1_xgt, xgt_score = XGBoostmodel(train_x, train_y, test_x, test_y)\n",
        "print(\"\\nTest Data:\\nAccuracy : {0}\\nPrecision : {1}\\nRecall : {2}\\nF1 : {3}\\nCross validation Score : {4}\".format(accuracy_xgt, precision_xgt, recall_xgt, f1_xgt, xgt_score))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing results for XG Boost:\n",
            "\n",
            "Training Data:\n",
            "Accuracy : 0.644043321299639\n",
            "Precision : 0.644043321299639\n",
            "Recall : 0.644043321299639\n",
            "F1 : 0.644043321299639\n",
            "Cross validation Score : 0.5942498175372745\n",
            "\n",
            "Test Data:\n",
            "Accuracy : 0.637211855104281\n",
            "Precision : 0.637211855104281\n",
            "Recall : 0.637211855104281\n",
            "F1 : 0.637211855104281\n",
            "Cross validation Score : 0.5942498175372745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8NM-n_b_m7E"
      },
      "source": [
        "**Comparing Accuracies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6xr_wJZ1C_O",
        "outputId": "c8a67cc8-1854-47a9-dc57-4e9fadcd2c97"
      },
      "source": [
        "print(\"Accuracies with Training data:\")\n",
        "print(\"\\nNaive Baiyes : {0:.2f}% \\nSVM model: {1:.2f}% \\nKNN Model: {2:.2f}%  \\nDecision Tree: {3:.2f}% \\nRandom Forest: {4:.2f}% \\nXG Boost: {5:.2f}% \".format(accuracy_nb * 100, accuracy_svm * 100, accuracy_knn * 100, accuracy_dt * 100, accuracy_rf * 100, accuracy_xg * 100 ))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracies with Training data:\n",
            "\n",
            "Naive Baiyes : 78.12% \n",
            "SVM model: 78.05% \n",
            "KNN Model: 73.72%  \n",
            "Decision Tree: 67.51% \n",
            "Random Forest: 75.38% \n",
            "XG Boost: 64.40% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RV7fP-q5lRz",
        "outputId": "8aa50953-d924-44d7-865f-00713802a0bb"
      },
      "source": [
        "print(\"Accuracies with Test data:\")\n",
        "print(\"\\nNaive Baiyes : {0:.2f}% \\nSVM model: {1:.2f}% \\nKNN Model: {2:.2f}%  \\nDecision Tree: {3:.2f}% \\nRandom Forest: {4:.2f}% \\nXG Boost: {5:.2f}% \".format(accuracy_nbt * 100, accuracy_svmt * 100, accuracy_knnt * 100, accuracy_dtt * 100, accuracy_rft * 100, accuracy_xgt * 100 ))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracies with Test data:\n",
            "\n",
            "Naive Baiyes : 78.54% \n",
            "SVM model: 79.31% \n",
            "KNN Model: 73.55%  \n",
            "Decision Tree: 67.73% \n",
            "Random Forest: 75.58% \n",
            "XG Boost: 63.72% \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}