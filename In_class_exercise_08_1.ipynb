{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_08-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ambicapvs/ambica_info5731_spring2021/blob/main/In_class_exercise_08_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n87IxFjR65WR"
      },
      "source": [
        "# **The eighth in-class-exercise (20 points in total, 3/30/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZkhXRYs65WS"
      },
      "source": [
        "The data for this exercise is from the dataset you created from assignment three. Please perform answer the following questions based on your data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD-RnBbe65WT"
      },
      "source": [
        "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVUBfQBb65WT",
        "outputId": "0e3f4701-308b-4db4-9bae-db8b4cd16253"
      },
      "source": [
        "!pip install polyglot\n",
        "!pip install pyicu\n",
        "!pip install pycld2\n",
        "!pip install morfessor\n",
        "!polyglot download sentiment2.en\n",
        "!pip install twython"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting polyglot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/98/e24e2489114c5112b083714277204d92d372f5bbe00d5507acf40370edb9/polyglot-16.7.4.tar.gz (126kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 17.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 23.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 26.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 26.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71kB 26.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 81kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 21.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 112kB 21.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122kB 21.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 21.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: polyglot\n",
            "  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52557 sha256=eb22865f9ee667cc1ad57ca4b3a6f00ad1c44fd68a4818c2903c2a544829f23c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/91/ef/f1369fdc1203b0a9347d4b24f149b83a305f39ab047986d9da\n",
            "Successfully built polyglot\n",
            "Installing collected packages: polyglot\n",
            "Successfully installed polyglot-16.7.4\n",
            "Collecting pyicu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/46/fa08c8efae2951e67681ec24319f789fc1a74e2096dd74373e34c79319de/PyICU-2.6.tar.gz (233kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 17.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyicu\n",
            "  Building wheel for pyicu (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyicu: filename=PyICU-2.6-cp37-cp37m-linux_x86_64.whl size=1306384 sha256=b64c6aa972c159c95a9f6eddbdd81fac3657c0f980c74c092fc004592de44d9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/21/2f/1c91831e8a93537ab21f6b4b935781b681104635fdb0315791\n",
            "Successfully built pyicu\n",
            "Installing collected packages: pyicu\n",
            "Successfully installed pyicu-2.6\n",
            "Collecting pycld2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/d2/8b0def84a53c88d0eb27c67b05269fbd16ad68df8c78849e7b5d65e6aec3/pycld2-0.41.tar.gz (41.4MB)\n",
            "\u001b[K     |████████████████████████████████| 41.4MB 111kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pycld2\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp37-cp37m-linux_x86_64.whl size=9834258 sha256=72602e58efd8b499295be4a152e423e082f9cea21855225df346c2552eafc81c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/8f/e9/08a1a8932a490175bd140206cd86a3dbcfc70498100de11079\n",
            "Successfully built pycld2\n",
            "Installing collected packages: pycld2\n",
            "Successfully installed pycld2-0.41\n",
            "Collecting morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Installing collected packages: morfessor\n",
            "Successfully installed morfessor-2.0.6\n",
            "[polyglot_data] Downloading package sentiment2.en to\n",
            "[polyglot_data]     /root/polyglot_data...\n",
            "Collecting twython\n",
            "  Downloading https://files.pythonhosted.org/packages/24/80/579b96dfaa9b536efde883d4f0df7ea2598a6f3117a6dd572787f4a2bcfb/twython-3.8.2-py3-none-any.whl\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from twython) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from twython) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.4.0->twython) (3.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (2.10)\n",
            "Installing collected packages: twython\n",
            "Successfully installed twython-3.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVBMIPa9FG5X",
        "outputId": "9dbe1e57-da4f-4921-cd89-c7ddcc6a2d4a"
      },
      "source": [
        "#loading data\n",
        "import pandas as pd\n",
        "dataframe = pd.read_csv(\"https://raw.githubusercontent.com/ambicapvs/ambica_info5731_spring2021/main/Q3(assig-3).csv\")\n",
        "dataframe['Review']"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Every once in a while a movie comes, that trul...\n",
              "1      This is a movie that only those who have felt ...\n",
              "2      Truly a masterpiece, The Best Hollywood film o...\n",
              "3      Joaquin Phoenix gives a tour de force performa...\n",
              "4      Most of the time movies are anticipated like t...\n",
              "                             ...                        \n",
              "101    One of the worst movies I have ever seen. Ok, ...\n",
              "102    I didnt really know much about this movie. I h...\n",
              "103    Film was directed and produced poorly. Opportu...\n",
              "104    Wow, what a movie! I have to admit, When I fir...\n",
              "105    This movie is poorly done as to how it tells t...\n",
              "Name: Review, Length: 106, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "e5RmDv-HIhOZ",
        "outputId": "cca41bf4-9177-425b-85ca-c600903d2a79"
      },
      "source": [
        "#sentiment term extraction and frequency\n",
        "import nltk\n",
        "import requests\n",
        "from textblob import TextBlob\n",
        "data = requests.get(\"https://gist.githubusercontent.com/sebleier/554280/raw/7e0e4a1ce04c2bb7bd41089c9821dbcf6d0c786c/NLTK's%2520list%2520of%2520english%2520stopwords\")\n",
        "a = data.text\n",
        "stop = a.split()\n",
        "#stopwords\n",
        "dataframe['stopwords'] = dataframe[\"Review\"].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "#lowercase\n",
        "dataframe[\"lower_case\"] = dataframe['stopwords'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "terms = []\n",
        "from polyglot.text import Text\n",
        "for b in dataframe[\"lower_case\"]:\n",
        "  item = Text(b)\n",
        "  for word in item.words:\n",
        "    if word.polarity != 0:\n",
        "      terms.append(word)\n",
        "      #print(word, word.polarity)\n",
        "\n",
        "from collections import Counter\n",
        "frequencies = Counter(terms)\n",
        "rankbyfreq = list(frequencies.most_common())\n",
        "#print(rankbyfreq)\n",
        "dataframerank = pd.DataFrame(rankbyfreq, columns =['term', 'frequency'])\n",
        "dataframerank"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>joker</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>like</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>good</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>best</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>disappointing</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>creepy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>unrealistic</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>pleasantly</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>anguish</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>523 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              term  frequency\n",
              "0            joker        143\n",
              "1             like         54\n",
              "2             good         54\n",
              "3             best         30\n",
              "4            great         28\n",
              "..             ...        ...\n",
              "518  disappointing          1\n",
              "519         creepy          1\n",
              "520    unrealistic          1\n",
              "521     pleasantly          1\n",
              "522        anguish          1\n",
              "\n",
              "[523 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS2GPFOg65WU"
      },
      "source": [
        "## (2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers. \n",
        "\n",
        "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "1z76zTFE65WU",
        "outputId": "900ff0fb-bedb-4ef8-89e3-e0c0dd3e93ad"
      },
      "source": [
        "#textblob\n",
        "from textblob import TextBlob\n",
        "textblobsentiment = []\n",
        "#Analysis with TextBlob\n",
        "for item in dataframe['lower_case']:\n",
        "  polarity = TextBlob(item).sentiment.polarity\n",
        "  if polarity > 0 :\n",
        "    textblobsentiment.append(\"positive\")\n",
        "  elif polarity < 0:\n",
        "    textblobsentiment.append(\"negative\")\n",
        "  elif polarity == 0:\n",
        "    textblobsentiment.append(\"neutral\")\n",
        "txtblobDataframe = pd.DataFrame(list(zip(dataframe['lower_case'], dataframe['sentiment'], textblobsentiment)), columns = ['Reviews', 'Actual', 'Predicted'])\n",
        "txtblobDataframe"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>every movie comes, truly makes impact. joaquin...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this movie felt alone isolated truly relate it...</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>truly masterpiece, the best hollywood film 201...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>joaquin phoenix gives tour de force performanc...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>most time movies anticipated like end falling ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>one worst movies i ever seen. ok, maybe hype s...</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>i didnt really know much movie. i hadnt seen t...</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>film directed produced poorly. opportunity tak...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>wow, movie! i admit, when i first heard joaqui...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>this movie poorly done tells story. it dark mo...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Reviews    Actual Predicted\n",
              "0    every movie comes, truly makes impact. joaquin...  positive  negative\n",
              "1    this movie felt alone isolated truly relate it...  positive   neutral\n",
              "2    truly masterpiece, the best hollywood film 201...  positive  positive\n",
              "3    joaquin phoenix gives tour de force performanc...  positive  negative\n",
              "4    most time movies anticipated like end falling ...  positive  positive\n",
              "..                                                 ...       ...       ...\n",
              "101  one worst movies i ever seen. ok, maybe hype s...  negative  positive\n",
              "102  i didnt really know much movie. i hadnt seen t...  negative  positive\n",
              "103  film directed produced poorly. opportunity tak...  negative  negative\n",
              "104  wow, movie! i admit, when i first heard joaqui...  positive  positive\n",
              "105  this movie poorly done tells story. it dark mo...  negative  negative\n",
              "\n",
              "[106 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_hh7ZFNIYu4",
        "outputId": "26e38e89-789c-4351-a2b8-2431acd3a1fe"
      },
      "source": [
        "#Calculate Accuracy and F1 Score for TextBlob Sentiment Analysis\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "txtblobaccuracy = accuracy_score(txtblobDataframe['Actual'], txtblobDataframe['Predicted'])*100\n",
        "txtblobscore = f1_score(txtblobDataframe['Actual'], txtblobDataframe['Predicted'], average = 'macro')\n",
        "print(\"TextBlob \\nAccuracy: \",txtblobaccuracy,\"\\nF1 Score: \", txtblobscore)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TextBlob \n",
            "Accuracy:  59.43396226415094 \n",
            "F1 Score:  0.4642388150862728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "A7CAyZB8Ieu3",
        "outputId": "7573f651-1b11-49f6-a641-2689f6d27263"
      },
      "source": [
        "#VADER Sentiment Analysis\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "vader = SentimentIntensityAnalyzer()\n",
        "vadersentiment = []\n",
        "for line in dataframe['lower_case']:\n",
        "  polarity = vader.polarity_scores(line)\n",
        "  if polarity['compound'] > 0 :\n",
        "    vadersentiment.append(\"positive\")\n",
        "  elif polarity['compound'] < 0:\n",
        "    vadersentiment.append(\"negative\")\n",
        "  elif polarity['compound'] == 0:\n",
        "    vadersentiment.append(\"neutral\")\n",
        "#vadersentiment\n",
        "vaderDataframe = pd.DataFrame(list(zip(dataframe['lower_case'], dataframe['sentiment'], vadersentiment)), columns = ['Reviews', 'Actual', 'Predicted'])\n",
        "vaderDataframe"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>every movie comes, truly makes impact. joaquin...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this movie felt alone isolated truly relate it...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>truly masterpiece, the best hollywood film 201...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>joaquin phoenix gives tour de force performanc...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>most time movies anticipated like end falling ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>one worst movies i ever seen. ok, maybe hype s...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>i didnt really know much movie. i hadnt seen t...</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>film directed produced poorly. opportunity tak...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>wow, movie! i admit, when i first heard joaqui...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>this movie poorly done tells story. it dark mo...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Reviews    Actual Predicted\n",
              "0    every movie comes, truly makes impact. joaquin...  positive  positive\n",
              "1    this movie felt alone isolated truly relate it...  positive  positive\n",
              "2    truly masterpiece, the best hollywood film 201...  positive  positive\n",
              "3    joaquin phoenix gives tour de force performanc...  positive  positive\n",
              "4    most time movies anticipated like end falling ...  positive  negative\n",
              "..                                                 ...       ...       ...\n",
              "101  one worst movies i ever seen. ok, maybe hype s...  negative  negative\n",
              "102  i didnt really know much movie. i hadnt seen t...  negative  positive\n",
              "103  film directed produced poorly. opportunity tak...  negative  negative\n",
              "104  wow, movie! i admit, when i first heard joaqui...  positive  positive\n",
              "105  this movie poorly done tells story. it dark mo...  negative  negative\n",
              "\n",
              "[106 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYDS0SJkLX_m",
        "outputId": "2758e88e-8b66-4af0-cfcd-d2cf03fd3d25"
      },
      "source": [
        "#Calculate Accuracy and F1 Score for VADER Sentiment Analysis\n",
        "vaderaccuracy = accuracy_score(vaderDataframe['Actual'], vaderDataframe['Predicted'])*100\n",
        "vaderscore = f1_score(vaderDataframe['Actual'], vaderDataframe['Predicted'], average = 'macro')\n",
        "print(\"VADER \\nAccuracy: \",vaderaccuracy,\"\\nF1 Score: \", vaderscore)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VADER \n",
            "Accuracy:  63.20754716981132 \n",
            "F1 Score:  0.4611599551358587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQxq6YKDLwzG",
        "outputId": "20189037-0c94-4c38-e765-24f9117a16b7"
      },
      "source": [
        "#SVM Analysis\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#Reference - https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34\n",
        "Train_X, Test_X, Train_Y, Test_Y = train_test_split(dataframe['Review'],dataframe['sentiment'],test_size=0.3)\n",
        "Encoder = LabelEncoder()\n",
        "Train_Y = Encoder.fit_transform(Train_Y)\n",
        "Test_Y = Encoder.fit_transform(Test_Y)\n",
        "Tfidf_vect = TfidfVectorizer(max_features= 5000, use_idf = True )\n",
        "Train_X_vectors = Tfidf_vect.fit_transform(Train_X)\n",
        "Test_X_vectors = Tfidf_vect.transform(Test_X)\n",
        "\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report\n",
        "svm_model = svm.SVC(kernel='linear')\n",
        "svm_model.fit(Train_X_vectors, Train_Y)\n",
        "predicted = svm_model.predict(Test_X_vectors)\n",
        "\n",
        "report = classification_report(Test_Y, predicted, output_dict=True, zero_division=0  )\n",
        "print(\"SVM \\nAccuracy: \",accuracy_score(predicted, Test_Y)*100, \"\\nF1 score\", report['macro avg']['f1-score'], \"\\n\\n\" )\n",
        "report\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM \n",
            "Accuracy:  65.625 \n",
            "F1 score 0.46606334841628955 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'f1-score': 0.7058823529411764,\n",
              "  'precision': 0.6,\n",
              "  'recall': 0.8571428571428571,\n",
              "  'support': 14},\n",
              " '1': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 4},\n",
              " '2': {'f1-score': 0.6923076923076924,\n",
              "  'precision': 0.75,\n",
              "  'recall': 0.6428571428571429,\n",
              "  'support': 14},\n",
              " 'accuracy': 0.65625,\n",
              " 'macro avg': {'f1-score': 0.46606334841628955,\n",
              "  'precision': 0.45,\n",
              "  'recall': 0.5,\n",
              "  'support': 32},\n",
              " 'weighted avg': {'f1-score': 0.6117081447963801,\n",
              "  'precision': 0.590625,\n",
              "  'recall': 0.65625,\n",
              "  'support': 32}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc8M_gEqcX_4"
      },
      "source": [
        "The F1 score and accuracy of SVM is higher than the scores of textblob and vader. So SVM has better performance and \n",
        "then textblob and last vader in the order.\n",
        "\n"
      ]
    }
  ]
}