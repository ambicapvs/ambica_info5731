{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_08-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ambicapvs/ambica_info5731_spring2021/blob/main/In_class_exercise_08_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n87IxFjR65WR"
      },
      "source": [
        "# **The eighth in-class-exercise (20 points in total, 3/30/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZkhXRYs65WS"
      },
      "source": [
        "The data for this exercise is from the dataset you created from assignment three. Please perform answer the following questions based on your data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD-RnBbe65WT"
      },
      "source": [
        "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVUBfQBb65WT",
        "outputId": "12d04de5-b382-4581-8e71-2e9315aeb99a"
      },
      "source": [
        "!pip install polyglot\n",
        "!pip install pyicu\n",
        "!pip install pycld2\n",
        "!pip install morfessor\n",
        "!polyglot download sentiment2.en\n",
        "!pip install twython"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting polyglot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/98/e24e2489114c5112b083714277204d92d372f5bbe00d5507acf40370edb9/polyglot-16.7.4.tar.gz (126kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 20.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 22.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71kB 18.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 81kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 16.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 112kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 15.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: polyglot\n",
            "  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52557 sha256=848dbd60561da77ff049b95f7b7a0138145d3bc93323eaff57b771fda748ba40\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/91/ef/f1369fdc1203b0a9347d4b24f149b83a305f39ab047986d9da\n",
            "Successfully built polyglot\n",
            "Installing collected packages: polyglot\n",
            "Successfully installed polyglot-16.7.4\n",
            "Collecting pyicu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/46/fa08c8efae2951e67681ec24319f789fc1a74e2096dd74373e34c79319de/PyICU-2.6.tar.gz (233kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 16.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyicu\n",
            "  Building wheel for pyicu (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyicu: filename=PyICU-2.6-cp37-cp37m-linux_x86_64.whl size=1306434 sha256=e3c96a49e67c31372e95b997eb85106b60b2745d9d55dac2af9c38d04a91af6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/21/2f/1c91831e8a93537ab21f6b4b935781b681104635fdb0315791\n",
            "Successfully built pyicu\n",
            "Installing collected packages: pyicu\n",
            "Successfully installed pyicu-2.6\n",
            "Collecting pycld2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/d2/8b0def84a53c88d0eb27c67b05269fbd16ad68df8c78849e7b5d65e6aec3/pycld2-0.41.tar.gz (41.4MB)\n",
            "\u001b[K     |████████████████████████████████| 41.4MB 114kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pycld2\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp37-cp37m-linux_x86_64.whl size=9834296 sha256=b613e2a5404a09307c25797647401da490024fbba3a0a5da533f9516e18b141f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/8f/e9/08a1a8932a490175bd140206cd86a3dbcfc70498100de11079\n",
            "Successfully built pycld2\n",
            "Installing collected packages: pycld2\n",
            "Successfully installed pycld2-0.41\n",
            "Collecting morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Installing collected packages: morfessor\n",
            "Successfully installed morfessor-2.0.6\n",
            "[polyglot_data] Downloading package sentiment2.en to\n",
            "[polyglot_data]     /root/polyglot_data...\n",
            "Collecting twython\n",
            "  Downloading https://files.pythonhosted.org/packages/24/80/579b96dfaa9b536efde883d4f0df7ea2598a6f3117a6dd572787f4a2bcfb/twython-3.8.2-py3-none-any.whl\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from twython) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from twython) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.4.0->twython) (3.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (2020.12.5)\n",
            "Installing collected packages: twython\n",
            "Successfully installed twython-3.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "iVBMIPa9FG5X",
        "outputId": "c33af2d2-9058-4dcf-e0c0-7ed6fd5d3f1f"
      },
      "source": [
        "#loading data\n",
        "import pandas as pd\n",
        "dataframe = pd.read_csv(\"https://raw.githubusercontent.com/ambicapvs/ambica_info5731_spring2021/main/Q3(assig-3).csv\")\n",
        "dataframe"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ReviewID</th>\n",
              "      <th>Review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Every once in a while a movie comes, that trul...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>This is a movie that only those who have felt ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Truly a masterpiece, The Best Hollywood film o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Joaquin Phoenix gives a tour de force performa...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Most of the time movies are anticipated like t...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>102</td>\n",
              "      <td>One of the worst movies I have ever seen. Ok, ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>103</td>\n",
              "      <td>I didnt really know much about this movie. I h...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>104</td>\n",
              "      <td>Film was directed and produced poorly. Opportu...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>105</td>\n",
              "      <td>Wow, what a movie! I have to admit, When I fir...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>106</td>\n",
              "      <td>This movie is poorly done as to how it tells t...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     ReviewID                                             Review sentiment\n",
              "0           1  Every once in a while a movie comes, that trul...  positive\n",
              "1           2  This is a movie that only those who have felt ...  positive\n",
              "2           3  Truly a masterpiece, The Best Hollywood film o...  positive\n",
              "3           4  Joaquin Phoenix gives a tour de force performa...  positive\n",
              "4           5  Most of the time movies are anticipated like t...  positive\n",
              "..        ...                                                ...       ...\n",
              "101       102  One of the worst movies I have ever seen. Ok, ...  negative\n",
              "102       103  I didnt really know much about this movie. I h...  negative\n",
              "103       104  Film was directed and produced poorly. Opportu...  negative\n",
              "104       105  Wow, what a movie! I have to admit, When I fir...  positive\n",
              "105       106  This movie is poorly done as to how it tells t...  negative\n",
              "\n",
              "[106 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "e5RmDv-HIhOZ",
        "outputId": "52e7aaee-df59-4c5b-cd9e-266f6ab802c0"
      },
      "source": [
        "#sentiment term extraction and frequency\n",
        "import nltk\n",
        "import requests\n",
        "from textblob import TextBlob\n",
        "data = requests.get(\"https://gist.githubusercontent.com/sebleier/554280/raw/7e0e4a1ce04c2bb7bd41089c9821dbcf6d0c786c/NLTK's%2520list%2520of%2520english%2520stopwords\")\n",
        "a = data.text\n",
        "stop = a.split()\n",
        "#stopwords\n",
        "dataframe['stopwords'] = dataframe[\"Review\"].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "#lowercase\n",
        "dataframe[\"lower_case\"] = dataframe['stopwords'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "terms = []\n",
        "from polyglot.text import Text\n",
        "for items in dataframe[\"lower_case\"]:\n",
        "  item = Text(items)\n",
        "  for word in item.words:\n",
        "    if word.polarity != 0:\n",
        "      terms.append(word)\n",
        "      #print(word, word.polarity)\n",
        "\n",
        "from collections import Counter\n",
        "frequencies = Counter(terms)\n",
        "rankbyfreq = list(frequencies.most_common())\n",
        "#print(rankbyfreq)\n",
        "dataframerank = pd.DataFrame(rankbyfreq, columns =['term', 'frequency'])\n",
        "dataframerank"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>joker</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>like</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>good</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>best</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>disappointing</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>creepy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>unrealistic</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>pleasantly</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>anguish</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>523 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              term  frequency\n",
              "0            joker        143\n",
              "1             like         54\n",
              "2             good         54\n",
              "3             best         30\n",
              "4            great         28\n",
              "..             ...        ...\n",
              "518  disappointing          1\n",
              "519         creepy          1\n",
              "520    unrealistic          1\n",
              "521     pleasantly          1\n",
              "522        anguish          1\n",
              "\n",
              "[523 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS2GPFOg65WU"
      },
      "source": [
        "## (2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers. \n",
        "\n",
        "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "1z76zTFE65WU",
        "outputId": "462e915e-d2ea-45c1-af90-27a79949f8aa"
      },
      "source": [
        "#Sentiment Analysis with TextBlob\n",
        "from textblob import TextBlob\n",
        "textblobsentiment = []\n",
        "for item in dataframe['lower_case']:\n",
        "  polarity = TextBlob(item).sentiment.polarity\n",
        "  if polarity > 0 :\n",
        "    textblobsentiment.append(\"positive\")\n",
        "  elif polarity < 0:\n",
        "    textblobsentiment.append(\"negative\")\n",
        "  elif polarity == 0:\n",
        "    textblobsentiment.append(\"neutral\")\n",
        "sentimentDataframe = pd.DataFrame(list(zip(dataframe['lower_case'], dataframe['sentiment'], textblobsentiment)), columns = ['Review', 'Actual', 'TextBlobPredicted'])\n",
        "sentimentDataframe"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Actual</th>\n",
              "      <th>TextBlobPredicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>every movie comes, truly makes impact. joaquin...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this movie felt alone isolated truly relate it...</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>truly masterpiece, the best hollywood film 201...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>joaquin phoenix gives tour de force performanc...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>most time movies anticipated like end falling ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>one worst movies i ever seen. ok, maybe hype s...</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>i didnt really know much movie. i hadnt seen t...</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>film directed produced poorly. opportunity tak...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>wow, movie! i admit, when i first heard joaqui...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>this movie poorly done tells story. it dark mo...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Review  ... TextBlobPredicted\n",
              "0    every movie comes, truly makes impact. joaquin...  ...          negative\n",
              "1    this movie felt alone isolated truly relate it...  ...           neutral\n",
              "2    truly masterpiece, the best hollywood film 201...  ...          positive\n",
              "3    joaquin phoenix gives tour de force performanc...  ...          negative\n",
              "4    most time movies anticipated like end falling ...  ...          positive\n",
              "..                                                 ...  ...               ...\n",
              "101  one worst movies i ever seen. ok, maybe hype s...  ...          positive\n",
              "102  i didnt really know much movie. i hadnt seen t...  ...          positive\n",
              "103  film directed produced poorly. opportunity tak...  ...          negative\n",
              "104  wow, movie! i admit, when i first heard joaqui...  ...          positive\n",
              "105  this movie poorly done tells story. it dark mo...  ...          negative\n",
              "\n",
              "[106 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_hh7ZFNIYu4",
        "outputId": "ecaade19-392d-4d00-dd4e-5137b85cefc5"
      },
      "source": [
        "#Calculate Accuracy and F1 Score for TextBlob Sentiment Analysis\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "txtblobaccuracy = accuracy_score(sentimentDataframe['Actual'], sentimentDataframe['TextBlobPredicted'])*100\n",
        "txtblobscore = f1_score(sentimentDataframe['Actual'], sentimentDataframe['TextBlobPredicted'], average = 'macro')\n",
        "print(\"TextBlob \\nAccuracy: \",txtblobaccuracy,\"\\nF1 Score: \", txtblobscore)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TextBlob \n",
            "Accuracy:  59.43396226415094 \n",
            "F1 Score:  0.4642388150862728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "A7CAyZB8Ieu3",
        "outputId": "7c97e42d-c009-4a47-8d8d-d4d989651fa1"
      },
      "source": [
        "#VADER Sentiment Analysis\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "vader = SentimentIntensityAnalyzer()\n",
        "vadersentiment = []\n",
        "for line in dataframe['lower_case']:\n",
        "  polarity = vader.polarity_scores(line)\n",
        "  if polarity['compound'] > 0 :\n",
        "    vadersentiment.append(\"positive\")\n",
        "  elif polarity['compound'] < 0:\n",
        "    vadersentiment.append(\"negative\")\n",
        "  elif polarity['compound'] == 0:\n",
        "    vadersentiment.append(\"neutral\")\n",
        "#vadersentiment\n",
        "sentimentDataframe['VaderPredicted'] = vadersentiment\n",
        "sentimentDataframe"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Actual</th>\n",
              "      <th>TextBlobPredicted</th>\n",
              "      <th>VaderPredicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>every movie comes, truly makes impact. joaquin...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this movie felt alone isolated truly relate it...</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>truly masterpiece, the best hollywood film 201...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>joaquin phoenix gives tour de force performanc...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>most time movies anticipated like end falling ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>one worst movies i ever seen. ok, maybe hype s...</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>i didnt really know much movie. i hadnt seen t...</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>film directed produced poorly. opportunity tak...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>wow, movie! i admit, when i first heard joaqui...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>this movie poorly done tells story. it dark mo...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Review  ... VaderPredicted\n",
              "0    every movie comes, truly makes impact. joaquin...  ...       positive\n",
              "1    this movie felt alone isolated truly relate it...  ...       positive\n",
              "2    truly masterpiece, the best hollywood film 201...  ...       positive\n",
              "3    joaquin phoenix gives tour de force performanc...  ...       positive\n",
              "4    most time movies anticipated like end falling ...  ...       negative\n",
              "..                                                 ...  ...            ...\n",
              "101  one worst movies i ever seen. ok, maybe hype s...  ...       negative\n",
              "102  i didnt really know much movie. i hadnt seen t...  ...       positive\n",
              "103  film directed produced poorly. opportunity tak...  ...       negative\n",
              "104  wow, movie! i admit, when i first heard joaqui...  ...       positive\n",
              "105  this movie poorly done tells story. it dark mo...  ...       negative\n",
              "\n",
              "[106 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYDS0SJkLX_m",
        "outputId": "292b8688-ba53-4c5e-8711-1c776a5c9b08"
      },
      "source": [
        "#Calculate Accuracy and F1 Score for VADER Sentiment Analysis\n",
        "vaderaccuracy = accuracy_score(sentimentDataframe['Actual'], sentimentDataframe['VaderPredicted'])*100\n",
        "vaderscore = f1_score(sentimentDataframe['Actual'], sentimentDataframe['VaderPredicted'], average = 'macro')\n",
        "print(\"VADER \\nAccuracy: \",vaderaccuracy,\"\\nF1 Score: \", vaderscore)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VADER \n",
            "Accuracy:  63.20754716981132 \n",
            "F1 Score:  0.4611599551358587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQxq6YKDLwzG",
        "outputId": "e0b77310-b6d1-42b5-aed4-be8df1e6dc95"
      },
      "source": [
        "#SVM Analysis\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#Reference - https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34\n",
        "Train_X, Test_X, Train_Y, Test_Y = train_test_split(dataframe['Review'],dataframe['sentiment'],test_size=0.3)\n",
        "Encoder = LabelEncoder()\n",
        "Train_Y = Encoder.fit_transform(Train_Y)\n",
        "Test_Y = Encoder.fit_transform(Test_Y)\n",
        "Tfidf_vect = TfidfVectorizer(max_features= 5000, use_idf = True )\n",
        "Train_X_vectors = Tfidf_vect.fit_transform(Train_X)\n",
        "Test_X_vectors = Tfidf_vect.transform(Test_X)\n",
        "\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report\n",
        "svm_model = svm.SVC(kernel='linear')\n",
        "svm_model.fit(Train_X_vectors, Train_Y)\n",
        "predicted = svm_model.predict(Test_X_vectors)\n",
        "svmreport = classification_report(Test_Y, predicted, output_dict=True, zero_division=0  )\n",
        "print(\"SVM \\nAccuracy: \",accuracy_score(predicted, Test_Y)*100, \"\\nF1 score\", svmreport['macro avg']['f1-score'], \"\\n\\n\" )\n",
        "svmreport\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM \n",
            "Accuracy:  68.75 \n",
            "F1 score 0.5186104218362283 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'f1-score': 0.7096774193548386,\n",
              "  'precision': 0.6470588235294118,\n",
              "  'recall': 0.7857142857142857,\n",
              "  'support': 14},\n",
              " '1': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 7},\n",
              " '2': {'f1-score': 0.846153846153846,\n",
              "  'precision': 0.7333333333333333,\n",
              "  'recall': 1.0,\n",
              "  'support': 11},\n",
              " 'accuracy': 0.6875,\n",
              " 'macro avg': {'f1-score': 0.5186104218362283,\n",
              "  'precision': 0.46013071895424834,\n",
              "  'recall': 0.5952380952380952,\n",
              "  'support': 32},\n",
              " 'weighted avg': {'f1-score': 0.6013492555831265,\n",
              "  'precision': 0.535171568627451,\n",
              "  'recall': 0.6875,\n",
              "  'support': 32}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc8M_gEqcX_4"
      },
      "source": [
        "**Performance Comparison**\n",
        "\n",
        "The Accuracy of SVM is higher than the scores of VADER and textblob. \n",
        "So, if accuracy is used as a measure SVM is preferred over VADER and Textblob in the order. \n",
        "\n",
        "The F1 score of SVM is higher than the scores of textblob and VADER. \n",
        "So, if F1 score is used as a measure SVM is preferred over Textblob and VADER in the order. \n",
        "\n",
        "\n",
        "ref:  https://medium.com/analytics-vidhya/accuracy-vs-f1-score-6258237beca2 \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}